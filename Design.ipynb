{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Convolutional Neural Networks) are consists of five components:\n",
    "\n",
    "- The input layer requires data inputted for preprocessing operations,  therefore, we transform the data shape from 3 dimension to 4 dimension. \n",
    "- The convolution layer introduce a concept of local perception, which tells that in the process of the human brain recognizing a picture, the whole picture is not recognized at the same time, but each feature in the picture is first perceived locally, and then the local operation is comprehensively performed at a higher level to obtain global information. We construct a CNN model that has three convolution layer, the first two convolution layer use 16 filters and the kernel size is 5 * 5. And the third convolution layer adopt one 1 * 1 kernel size aiming to reduce the dimension of image.\n",
    "- The activation layer makes a non-linear mapping of the output of the convolution layer. In this model, we choose the ReLU function, because iteration is faster.\n",
    "- The pooling layer mainly used for feature dimension reduction, compressing the number of data and parameters, reducing overfitting, and improving the fault tolerance of the model. We choose a max pooling over a (2, 2) window. Finally, the feature maps are converted to a 1-dimensional vector by up sampling and the third convolution layer.\n",
    "- The output layer which also called fully connected layer. After several previous convolutions, activations, and pooling, the model will fully learn a high-quality feature picture fully connected layer.\n",
    "\n",
    "CNN can directly process grayscale images and can be used directly to process image-based classification. CNN has unique advantages in image processing due to its special structure of local weight sharing. The layout is closer to the real biological neural network. Weight sharing reduces the complexity of the network, especially for multidimensional input vectors. The feature that allows images to be directly entered on the network avoids the complexity of rebuilding data when retrieving and classifying features.Maybe the performance of CNN used for MRI processing is  not well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #  conv1层，输入的灰度图，所以 in_channels=1, out_channels=6 说明使用了6个滤波器/卷积核，\n",
    "        # kernel_size=5卷积核大小5x5\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5 ,stride = 1,padding = 2)\n",
    "        # conv2层， 输入通道in_channels 要等于上一层的 out_channels\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5,stride = 1,padding = 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=1,stride = 1)\n",
    "        # an affine operarion: y = Wx + b\n",
    "        # 全连接层fc1,因为32x32图像输入到fc1层时候，feature map为： 5x5x16\n",
    "        # 因此，全连接层的输入特征维度为16*5*5，  因为上一层conv2的out_channels=16\n",
    "        # out_features=84,输出维度为84，代表该层为84个神经元\n",
    "        self.upsample = nn.Upsample(scale_factor=4, mode='bilinear',align_corners=False)\n",
    "\n",
    "#         self.fc1 = nn.Linear(1*32*80*80, 120)\n",
    "#         self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "#         self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # 特征图转换为一个１维的向量\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv3(x)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]     # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "model = Net()\n",
    "#print(model)\n",
    "# Try a random 32x32 input\n",
    "\n",
    "# input = torch.randn(1, 1, 320, 320)\n",
    "# out = model(input)\n",
    "# print(out.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loss_func = nn.CrossEntropyLoss()\n",
    "# opt = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 U-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-NET model are mainly composed of two parts :\n",
    "\n",
    "- Feature extraction part is also called the down sampling. Every time we go through the pooling layer, we think that the scale is increased by one. Firstly, each convolutional layer contains two convolution operations, and then we encapsulate these two convolution layers into a class ConvBlock. Specifically, each convolution layer followed by kernel, instance normalization, ReLU activation and drop out, kernel size is 3 * 3 and the number of channels doubles after the first convolution operation, and remains the same the second time. Dropout is often used to randomly delete some neurons in a neural network to prevent overfitting and optimize the model by using normalization at the same time. After two convolution layers, We choose a max pooling over a (2, 2) window used to process feature map. The number of pool layers depends on experimenters.\n",
    "- Up sampling is a critical part of U-net. Up sampling requires the feature map merged at the same scale as the number of channels corresponding to the feature extraction part. Therefore, before merging, the model will copy and crop the feature map in the shallow layers, which results in the final output is a region in the center of the input. And then passing through ConvBlock. Finally, in the last layer, we use the kernel 1 * 1 to accept the output image.\n",
    "\n",
    "U-NET is derived from CNN. U-shaped structure is the biggest feature of U-NET. U-NET performs several down sampling and use the contact connection on the corresponding layer, which ensured that the finally recovered feature maps incorporated more low-level features. Multiple up sampling also makes the information such as edge restoration of the image more detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, relu activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input.\n",
    "            out_chans (int): Number of channels in the output.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        return self.layers(input)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'ConvBlock(in_chans={self.in_chans}, out_chans={self.out_chans}, ' \\\n",
    "            f'drop_prob={self.drop_prob})'\n",
    "\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model.\n",
    "\n",
    "    This is based on:\n",
    "        Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks\n",
    "        for biomedical image segmentation. In International Conference on Medical image\n",
    "        computing and computer-assisted intervention, pages 234–241. Springer, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, chans, num_pool_layers, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input to the U-Net model.\n",
    "            out_chans (int): Number of channels in the output to the U-Net model.\n",
    "            chans (int): Number of output channels of the first convolution layer.\n",
    "            num_pool_layers (int): Number of down-sampling and up-sampling layers.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
    "        ch = chans\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.down_sample_layers += [ConvBlock(ch, ch * 2, drop_prob)]\n",
    "            ch *= 2\n",
    "        self.conv = ConvBlock(ch, ch, drop_prob)\n",
    "\n",
    "        self.up_sample_layers = nn.ModuleList()\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.up_sample_layers += [ConvBlock(ch * 2, ch // 2, drop_prob)]\n",
    "            ch //= 2\n",
    "        self.up_sample_layers += [ConvBlock(ch * 2, ch, drop_prob)]\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch // 2, kernel_size=1),\n",
    "            nn.Conv2d(ch // 2, out_chans, kernel_size=1),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        stack = []\n",
    "        output = input\n",
    "        # Apply down-sampling layers\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output)\n",
    "            stack.append(output)\n",
    "            output = F.max_pool2d(output, kernel_size=2)\n",
    "\n",
    "        output = self.conv(output)\n",
    "\n",
    "        # Apply up-sampling layers\n",
    "        for layer in self.up_sample_layers:\n",
    "            output = F.interpolate(output, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            output = torch.cat([output, stack.pop()], dim=1)\n",
    "            output = layer(output)\n",
    "        return self.conv2(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
